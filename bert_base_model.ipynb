{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"bert_base_model.ipynb","provenance":[{"file_id":"1XAThkmGIHNtA3Zh2swU8WUNe1CRiwCwO","timestamp":1606250659791}],"collapsed_sections":[],"machine_shape":"hm"},"coursera":{"schema_names":["NLPC3-4A"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"e977800756d546ffa8a586546c9beb45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_07002a329970463b961fcc072f3b68d5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d71804dc3f8e4698a641d951927addff","IPY_MODEL_b9a46eabb8ce439e8ffc6fa900cc70d6"]}},"07002a329970463b961fcc072f3b68d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d71804dc3f8e4698a641d951927addff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c0e6675fcea048758f2cf191bccf5930","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9111565eafdd44598e1821b5f7752d44"}},"b9a46eabb8ce439e8ffc6fa900cc70d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2dbfda1956274e96bfb1a146e48e100d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 315kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a8c045d826a4447e8d24a4ac1584371a"}},"c0e6675fcea048758f2cf191bccf5930":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9111565eafdd44598e1821b5f7752d44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2dbfda1956274e96bfb1a146e48e100d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a8c045d826a4447e8d24a4ac1584371a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f09ffbc0dfd848a49ec810b3a6b03531":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ed2c56c5f28f49a28de4d7c773b3a49f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0cf42119a2d64d09adae13b9382574ea","IPY_MODEL_af79a9d6bd9e4848981ac36e4b072710"]}},"ed2c56c5f28f49a28de4d7c773b3a49f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0cf42119a2d64d09adae13b9382574ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f9e63bc23b834cb88733081f3518e4a8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01efd889b9c54ac5b2154e84592dee34"}},"af79a9d6bd9e4848981ac36e4b072710":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ebba6cb0a9c34800abe456f9ab63911e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:25&lt;00:00, 17.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_43284fe771cf409185aa9e615ae74dfe"}},"f9e63bc23b834cb88733081f3518e4a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"01efd889b9c54ac5b2154e84592dee34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebba6cb0a9c34800abe456f9ab63911e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"43284fe771cf409185aa9e615ae74dfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c99a5563241b40529aa2a00ad15ee64e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_494efdfe6e7f4760afe10f9729e947f7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7e19a8ae1cbc4a46839538991e5abb90","IPY_MODEL_fe125ce12e2b4f41988034db29b9a4be"]}},"494efdfe6e7f4760afe10f9729e947f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7e19a8ae1cbc4a46839538991e5abb90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_504e107113cc4685bf14aef603f1ca07","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":536063208,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":536063208,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_566997794578414693ab91e987dd6be9"}},"fe125ce12e2b4f41988034db29b9a4be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cffe99d776ca45d5b5c2a42ffb3f9ed1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 536M/536M [00:24&lt;00:00, 21.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a5d1dda5e5364c3abda885575b619d56"}},"504e107113cc4685bf14aef603f1ca07":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"566997794578414693ab91e987dd6be9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cffe99d776ca45d5b5c2a42ffb3f9ed1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a5d1dda5e5364c3abda885575b619d56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57efcb3b92cd43c08e0fedd91e6c28df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_df34638e9a494002b5cb2454a08a9918","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b6492dd934d041e78cd8704d3d7d80c6","IPY_MODEL_24c1ea743636467d9af1aab337b1ff0d"]}},"df34638e9a494002b5cb2454a08a9918":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b6492dd934d041e78cd8704d3d7d80c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2a2edf2645354b7dad81ae5af85e8784","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82e7833c86df47aa9d192dde709ad7f9"}},"24c1ea743636467d9af1aab337b1ff0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_141fe4fe0f4248989440873e4be1bb78","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 821kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b3d3fb721f92470091d6958e9772e8a3"}},"2a2edf2645354b7dad81ae5af85e8784":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"82e7833c86df47aa9d192dde709ad7f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"141fe4fe0f4248989440873e4be1bb78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b3d3fb721f92470091d6958e9772e8a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llTFOgQy9iYj","executionInfo":{"status":"ok","timestamp":1607614003970,"user_tz":-360,"elapsed":1621,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"416d0688-bd1a-452a-f34d-372adddf37db"},"source":["# connected GPU information\n","!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Dec 10 15:26:44 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    26W / 250W |      1MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jdG8TWva4fpa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607614046794,"user_tz":-360,"elapsed":39810,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"2d6a9ade-ced4-4da8-b095-f636e66c5b43"},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XhY0C80ISa-F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607614065869,"user_tz":-360,"elapsed":8764,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"89dc0b00-3e97-4519-9f9e-921fdb098867"},"source":["# install huggingface transformers\n","!pip -q install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.4MB 5.3MB/s \n","\u001b[K     |████████████████████████████████| 890kB 32.5MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 45.1MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zdACgs491cs2","executionInfo":{"status":"ok","timestamp":1607614070817,"user_tz":-360,"elapsed":12940,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["import os\n","\n","import tensorflow as tf\n","import transformers\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","\n","import random as rnd"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ui7sHLhTEq2D","executionInfo":{"status":"ok","timestamp":1607614070819,"user_tz":-360,"elapsed":11969,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4sF9Hqzgwt0l"},"source":["<a name='1'></a>\n","#Importing the Data"]},{"cell_type":"code","metadata":{"id":"sXWBVGWnpity","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1607614074094,"user_tz":-360,"elapsed":11920,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"e1ce112e-d568-4083-950c-17eaec2f8d96"},"source":["data = pd.read_csv(\"/content/drive/My Drive/Duplicate Question Detection/\"+\n","                   \"quora_questions.csv\")\n","#data.fillna(\"none value\", inplace=True) # replace nan value to none\n","# drop the rows with null value\n","data.dropna(axis=0, inplace=True)\n","N=len(data)\n","print('Number of question pairs: ', N)\n","data.head()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Number of question pairs:  404348\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  ...                                          question2 is_duplicate\n","0   0     1  ...  What is the step by step guide to invest in sh...            0\n","1   1     3  ...  What would happen if the Indian government sto...            0\n","2   2     5  ...  How can Internet speed be increased by hacking...            0\n","3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n","4   4     9  ...            Which fish would survive in salt water?            0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"yMLgpExkBY6g"},"source":["# def cut_to_max(text, max_len):\n","#     words = text.split()[:max_len]\n","#     return ' '.join(words)\n","\n","# # test the func\n","# # cut_to_max(' abc test wewe dfd ddd', 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"deYmlI46IvjG"},"source":["# data['question1'] = data['question1'].apply(lambda x: cut_to_max(x, 65))\n","# data['question2'] = data['question2'].apply(lambda x: cut_to_max(x, 65))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"da9RE9hnMcej"},"source":["# for s in data['question2']:\n","#     if len(s.split()) > 65:\n","#         print(s)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktQColfXYdXS","executionInfo":{"status":"ok","timestamp":1606439220142,"user_tz":-360,"elapsed":1297,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"1f45611e-54f0-43db-ee98-1dd908c96235"},"source":["print(\"dataset labels Distribution\")\n","print(data.is_duplicate.value_counts())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dataset labels Distribution\n","0    255042\n","1    149306\n","Name: is_duplicate, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gkSQTu7Ypit0"},"source":["We first split the data into a train and test set. The test set will be used later to evaluate our model."]},{"cell_type":"code","metadata":{"id":"dkKiI0gip6Qs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607614204043,"user_tz":-360,"elapsed":1643,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"1781494c-7648-4fd8-9f6a-66ea9d0a0ad4"},"source":["# model selection\n","from sklearn.model_selection import train_test_split\n","data_train , data_test = train_test_split(data, train_size=0.75, random_state=0)\n","# validation_data, _ = train_test_split(data_train, train_size=0.1, random_state=0)\n","len(data_train), len(data_test)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(303261, 101087)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"vJQespJVZJKC"},"source":["# print(\"Train dataset Distribution\")\n","# print(data_train.is_duplicate.value_counts())\n","\n","# print(\"\\n\\nTest dataset Distribution\")\n","# print(data_test.is_duplicate.value_counts())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHpZO58Dss_v","executionInfo":{"status":"ok","timestamp":1607614209269,"user_tz":-360,"elapsed":2517,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["train_Q1 = np.array(data_train['question1'])\n","train_Q2 = np.array(data_train['question2'])\n","t_labels = np.array(data_train['is_duplicate'])\n","# make it one-hot encoding\n","train_labels = tf.keras.utils.to_categorical(t_labels, num_classes=2)\n","\n","test_Q1 = np.array(data_test['question1'])\n","test_Q2 = np.array(data_test['question2'])\n","te_labels  = np.array(data_test['is_duplicate'])\n","# make it one-hot encoding\n","test_labels = tf.keras.utils.to_categorical(te_labels, num_classes=2)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"6t-fu-fL-qf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606492541348,"user_tz":-360,"elapsed":1399,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"bb8cba03-5198-4b4f-b71c-6aa5bbd03055"},"source":["train_Q1.shape, train_Q2.shape, train_labels.shape, test_Q1.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((303261,), (303261,), (303261, 2), (101087,))"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"AOnRiPN4CwSF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606493400260,"user_tz":-360,"elapsed":1848,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"00ec4666-0284-499b-8a35-a0ecd14143d0"},"source":["# max = 65\n","# i_mx = 0\n","# for i, w in enumerate(data['question2']):\n","#     if len(w.split()) > max:\n","#         i_mx += 1\n","\n","# print(i_mx)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A2bdHKgJYZ7U","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e977800756d546ffa8a586546c9beb45","07002a329970463b961fcc072f3b68d5","d71804dc3f8e4698a641d951927addff","b9a46eabb8ce439e8ffc6fa900cc70d6","c0e6675fcea048758f2cf191bccf5930","9111565eafdd44598e1821b5f7752d44","2dbfda1956274e96bfb1a146e48e100d","a8c045d826a4447e8d24a4ac1584371a"]},"executionInfo":{"status":"ok","timestamp":1607614236944,"user_tz":-360,"elapsed":3634,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"57b5a32f-6629-42b6-f611-0e400f4f8726"},"source":["# define model name\n","PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n","\n","# import tokenizer\n","tokenizer = transformers.BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=True)\n"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e977800756d546ffa8a586546c9beb45","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1M813a8pAGR","executionInfo":{"status":"ok","timestamp":1606496491050,"user_tz":-360,"elapsed":2328,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"b881b014-9766-4c49-9368-f46d9449bcd4"},"source":["# tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.unk_token_id, tokenizer.pad_token_id, tokenizer.mask_token_id"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(101, 102, 100, 0, 103)"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrrGq2oEpmog","executionInfo":{"status":"ok","timestamp":1606496464119,"user_tz":-360,"elapsed":2250,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"c1264a6b-ca9e-4fdd-eb95-7ccaf2764326"},"source":["# tokenizer.special_tokens_map"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'cls_token': '[CLS]',\n"," 'mask_token': '[MASK]',\n"," 'pad_token': '[PAD]',\n"," 'sep_token': '[SEP]',\n"," 'unk_token': '[UNK]'}"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"bz7H3hhIN_8T"},"source":["# data generator\n","class data_generator(tf.keras.utils.Sequence):\n","    \"\"\"Generates batches of data.\n","\n","    Args:\n","        sentence_pairs: Array of premise and hypothesis input sentences.\n","        labels: Array of labels.\n","        batch_size: Integer batch size.\n","        shuffle: boolean, whether to shuffle the data.\n","        include_targets: boolean, whether to incude the labels.\n","\n","    Returns:\n","        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n","        (or just `[input_ids, attention_mask, `token_type_ids]`\n","         if `include_targets=False`)\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        sentence_pairs,\n","        labels,\n","        batch_size,\n","        shuffle=True,\n","        include_targets=True,\n","    ):\n","        self.sentence_pairs = sentence_pairs\n","        self.labels = labels\n","        self.shuffle = shuffle\n","        self.batch_size = batch_size\n","        self.include_targets = include_targets\n","        # Load our BERT Tokenizer to encode the text.\n","        # We will use base-base-uncased pretrained model.\n","        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n","            \"bert-base-uncased\", do_lower_case=True\n","        )\n","        self.indexes = np.arange(len(self.sentence_pairs))\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        # Denotes the number of batches per epoch.\n","        return len(self.sentence_pairs) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        # Retrieves the batch of index.\n","        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        sentence_pairs = self.sentence_pairs[indexes]\n","\n","        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n","        # encoded together and separated by [SEP] token.\n","        encoded = self.tokenizer.batch_encode_plus(\n","            sentence_pairs.tolist(),\n","            add_special_tokens=True,\n","            max_length=max_length,\n","            return_attention_mask=True,\n","            return_token_type_ids=True,\n","            pad_to_max_length=True,\n","            return_tensors=\"tf\",\n","        )\n","\n","        # Convert batch of encoded features to numpy array.\n","        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n","        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n","        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n","\n","        # Set to true if data generator is used for training/validation.\n","        if self.include_targets:\n","            labels = np.array(self.labels[indexes], dtype=\"int32\")\n","            return [input_ids, attention_masks, token_type_ids], labels\n","        else:\n","            return [input_ids, attention_masks, token_type_ids]\n","\n","    def on_epoch_end(self):\n","        # Shuffle indexes after each epoch if shuffle is set to True.\n","        if self.shuffle:\n","            np.random.RandomState(42).shuffle(self.indexes)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4O-D3G2OABg"},"source":["# make a model for detecting duplicate question\n","# max_length = 256\n","# learning_rate = 0.001\n","def duplicate_question_detection_model():\n","\n","    # Encoded token ids from BERT tokenizer.\n","    input_ids = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n","    )\n","\n","    # Attention masks indicates to the model which tokens should be attended to.\n","    attention_masks = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n","    )\n","\n","    # Token type ids are binary masks identifying different sequences in the model.\n","    token_type_ids = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n","    )\n","\n","     # Loading pretrained BERT model.\n","    bert_model = transformers.TFBertModel.from_pretrained('bert-base-uncased')\n","    # Freeze the BERT model to reuse the pretrained features without modifying them.\n","    bert_model.trainable = False\n","\n","    sequence_output, pooled_output = bert_model(\n","        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n","    )\n","\n","    # Add dropout layer for regalarization \n","    #dropout_of_sequence_output = tf.keras.layers.Dropout(0.3)(sequence_output)\n","\n","    # print('sequence shape: ', sequence_output.shape)\n","\n","    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n","    bi_lstm = tf.keras.layers.Bidirectional(\n","        tf.keras.layers.LSTM(64, return_sequences=True)\n","    )(sequence_output)\n","    # reshaped_output = tf.keras.layers.Flatten()(bi_lstm)\n","    # dp1 = tf.keras.layers.Dropout(0.3)(reshaped_output)\n","    # dn1 = tf.keras.layers.Dense(128, activation='relu')(dp1)\n","\n","    # Applying hybrid pooling approach to bi_lstm sequence output.\n","    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n","    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n","    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n","    dropout = tf.keras.layers.Dropout(0.1)(concat)\n","    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n","\n","    # model object\n","    model = tf.keras.models.Model(\n","        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n","    )\n","\n","    # compile the model\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[\"acc\"],\n","    )\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":764,"referenced_widgets":["f09ffbc0dfd848a49ec810b3a6b03531","ed2c56c5f28f49a28de4d7c773b3a49f","0cf42119a2d64d09adae13b9382574ea","af79a9d6bd9e4848981ac36e4b072710","f9e63bc23b834cb88733081f3518e4a8","01efd889b9c54ac5b2154e84592dee34","ebba6cb0a9c34800abe456f9ab63911e","43284fe771cf409185aa9e615ae74dfe","c99a5563241b40529aa2a00ad15ee64e","494efdfe6e7f4760afe10f9729e947f7","7e19a8ae1cbc4a46839538991e5abb90","fe125ce12e2b4f41988034db29b9a4be","504e107113cc4685bf14aef603f1ca07","566997794578414693ab91e987dd6be9","cffe99d776ca45d5b5c2a42ffb3f9ed1","a5d1dda5e5364c3abda885575b619d56"]},"id":"Lk_4aHJPOBIU","executionInfo":{"status":"ok","timestamp":1606439284263,"user_tz":-360,"elapsed":38641,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"3e71c60c-00ee-4fa0-99f5-092b5a8c86bc"},"source":["# Create the model under a distribution strategy scope.\n","strategy = tf.distribute.MirroredStrategy()\n","\n","with strategy.scope():\n","    max_length=64\n","    learning_rate=0.001\n","    model = duplicate_question_detection_model()\n","\n","# print(f\"Strategy: {strategy}\")\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f09ffbc0dfd848a49ec810b3a6b03531","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c99a5563241b40529aa2a00ad15ee64e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","attention_masks (InputLayer)    [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","token_type_ids (InputLayer)     [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     ((None, 128, 768), ( 109482240   input_ids[0][0]                  \n","                                                                 attention_masks[0][0]            \n","                                                                 token_type_ids[0][0]             \n","__________________________________________________________________________________________________\n","bidirectional (Bidirectional)   (None, 128, 128)     426496      tf_bert_model[0][0]              \n","__________________________________________________________________________________________________\n","global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n","__________________________________________________________________________________________________\n","global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n","                                                                 global_max_pooling1d[0][0]       \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2)            514         dropout_37[0][0]                 \n","==================================================================================================\n","Total params: 109,909,250\n","Trainable params: 427,010\n","Non-trainable params: 109,482,240\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GTN9S3J9OBWe","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["57efcb3b92cd43c08e0fedd91e6c28df","df34638e9a494002b5cb2454a08a9918","b6492dd934d041e78cd8704d3d7d80c6","24c1ea743636467d9af1aab337b1ff0d","2a2edf2645354b7dad81ae5af85e8784","82e7833c86df47aa9d192dde709ad7f9","141fe4fe0f4248989440873e4be1bb78","b3d3fb721f92470091d6958e9772e8a3"]},"executionInfo":{"status":"ok","timestamp":1606439293938,"user_tz":-360,"elapsed":4079,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"08a37cba-6226-4242-8f0e-64b90ef1052e"},"source":["# data preparation\n","batch_size = 512\n","train_data = data_generator(\n","    data_train[[\"question1\", \"question2\"]].values.astype(\"str\"),\n","    train_labels,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","valid_data = data_generator(\n","    data_test[[\"question1\", \"question2\"]].values.astype(\"str\"),\n","    test_labels,\n","    batch_size=batch_size,\n","    shuffle=False,\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57efcb3b92cd43c08e0fedd91e6c28df","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16EfvUObOBoy","executionInfo":{"status":"ok","timestamp":1606448275892,"user_tz":-360,"elapsed":2783487,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"39b0152c-7547-4f56-a6fb-0c778b08d1b6"},"source":["epochs = 5\n","history = model.fit(\n","    train_data,\n","    validation_data=valid_data,\n","    epochs=epochs,\n","    use_multiprocessing=True,\n","    workers=-1,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/5\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Iterator.get_next_as_optional()` instead.\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","592/592 [==============================] - ETA: 0s - loss: 0.4174 - acc: 0.7935"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","592/592 [==============================] - 1791s 3s/step - loss: 0.4174 - acc: 0.7935 - val_loss: 0.3769 - val_acc: 0.8205\n","Epoch 2/5\n","592/592 [==============================] - 1787s 3s/step - loss: 0.3519 - acc: 0.8348 - val_loss: 0.3262 - val_acc: 0.8497\n","Epoch 3/5\n","592/592 [==============================] - 1786s 3s/step - loss: 0.3290 - acc: 0.8480 - val_loss: 0.3124 - val_acc: 0.8581\n","Epoch 4/5\n","592/592 [==============================] - 1785s 3s/step - loss: 0.3116 - acc: 0.8585 - val_loss: 0.3026 - val_acc: 0.8634\n","Epoch 5/5\n","592/592 [==============================] - 1786s 3s/step - loss: 0.2994 - acc: 0.8650 - val_loss: 0.2934 - val_acc: 0.8677\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IlUUr8FxU-B0"},"source":["model.save_weights('/content/drive/My Drive/Thesis/Duplicate Question/saved weights/model_weights.h5', overwrite=True, save_format=None, options=None)\n","# model.load_weights('/content/drive/My Drive/Thesis/Duplicate Question/saved weights/model_weights.h5', by_name=False, skip_mismatch=False, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXb8ZbnYPlT9"},"source":["# draw curves \n","import matplotlib.pyplot as plt\n","%pylab inline\n","plt.plot(history.history['loss'], label='train')\n","plt.plot(history.history['val_loss'], label='val')\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(history.history['acc'], label='train')\n","plt.plot(history.history['val_acc'], label='val')\n","plt.xlabel('epochs')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"95cVHTbO-beQ"},"source":["model.evaluate(valid_data, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NDCcLnd8pqiH"},"source":[""]}]}