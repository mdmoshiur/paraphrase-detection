{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BERT_for_sequence_classification.ipynb","provenance":[{"file_id":"10TWl8ZEOK4aFpXNxKGQ8sNTDe8TbnYee","timestamp":1606471759418},{"file_id":"1XAThkmGIHNtA3Zh2swU8WUNe1CRiwCwO","timestamp":1606250659791}],"collapsed_sections":[],"machine_shape":"hm"},"coursera":{"schema_names":["NLPC3-4A"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"b92fef2c773c466a81a673a56f816299":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b90adab80af04ea88f6241e6af362a2d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ef84839728654131b88b4b7ee687060a","IPY_MODEL_7010f61fd62e450182d24e4768a4d7a5"]}},"b90adab80af04ea88f6241e6af362a2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef84839728654131b88b4b7ee687060a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bb4fa3191d5048489fb7c449b36804df","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54dbaf6998664265a87404ba0927d393"}},"7010f61fd62e450182d24e4768a4d7a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_011e593c2f22481d863a3d8be9527653","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 869B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_755747d3bd63495481eb35d569126014"}},"bb4fa3191d5048489fb7c449b36804df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"54dbaf6998664265a87404ba0927d393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"011e593c2f22481d863a3d8be9527653":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"755747d3bd63495481eb35d569126014":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c609b49841f54e069b3327a8c8ece28e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f47edf4d74404a92b709d3fda84166d6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5e67bc35ee984194befe28431d740c85","IPY_MODEL_f9d07429dae149d5a0a32fff2f71ca94"]}},"f47edf4d74404a92b709d3fda84166d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e67bc35ee984194befe28431d740c85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ea0890b272b74206a7c4bddbcfb688e2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":526681800,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":526681800,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d36b461448b94dd39ff3d7f8c5e20da5"}},"f9d07429dae149d5a0a32fff2f71ca94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df8f4e6e796a4102a2ea3cdbef7fa1a2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 527M/527M [00:12&lt;00:00, 43.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4ce80f442ee4ae09eac29887a11e516"}},"ea0890b272b74206a7c4bddbcfb688e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d36b461448b94dd39ff3d7f8c5e20da5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df8f4e6e796a4102a2ea3cdbef7fa1a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b4ce80f442ee4ae09eac29887a11e516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc90e96ac81044238f9c5d3208c70cbf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8ddd56f7922a453988b79855449b64c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_566aa8d89c354de99e54e67e765cf664","IPY_MODEL_3d445822690249048e27bb7e5639f221"]}},"8ddd56f7922a453988b79855449b64c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"566aa8d89c354de99e54e67e765cf664":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d4539b61eec24e1d9de2b639e2eda4a8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1bc7832b3bc649279f7ed402ff1d0cdc"}},"3d445822690249048e27bb7e5639f221":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5236f3346efd4bee9b4e4124d1c06d42","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 537kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_825607e7d75c48b7aabcc8a155d85175"}},"d4539b61eec24e1d9de2b639e2eda4a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1bc7832b3bc649279f7ed402ff1d0cdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5236f3346efd4bee9b4e4124d1c06d42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"825607e7d75c48b7aabcc8a155d85175":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llTFOgQy9iYj","executionInfo":{"status":"ok","timestamp":1607427441702,"user_tz":-360,"elapsed":1118,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"3b6faf48-b272-47b6-a572-4c3eaf53fc93"},"source":["# connected GPU information\n","!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Tue Dec  8 11:37:21 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jdG8TWva4fpa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607427478619,"user_tz":-360,"elapsed":32479,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"f469dbc4-f60f-4993-bcfd-995f0fa2e9a1"},"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XhY0C80ISa-F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607427489726,"user_tz":-360,"elapsed":8393,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"3105ad51-c513-4c11-d785-e2d0bea58245"},"source":["# install huggingface transformers\n","!pip -q install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.4MB 5.2MB/s \n","\u001b[K     |████████████████████████████████| 890kB 17.5MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 26.8MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhvUdyCQXQjo","executionInfo":{"status":"ok","timestamp":1606927945207,"user_tz":-360,"elapsed":2053,"user":{"displayName":"Moshiur Rahman","photoUrl":"","userId":"06268589185065181981"}},"outputId":"c6a437ad-d6fd-44e5-8f7e-05bc0fd0da12"},"source":["!transformers --v"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/bin/bash: transformers: command not found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zdACgs491cs2","executionInfo":{"status":"ok","timestamp":1607427501037,"user_tz":-360,"elapsed":9748,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["import os\n","\n","import tensorflow as tf\n","import transformers\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","\n","import random as rnd"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ui7sHLhTEq2D","executionInfo":{"status":"ok","timestamp":1607420466124,"user_tz":-360,"elapsed":5729,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4sF9Hqzgwt0l"},"source":["<a name='1'></a>\n","#Importing the Data"]},{"cell_type":"code","metadata":{"id":"sXWBVGWnpity","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1607427505900,"user_tz":-360,"elapsed":3263,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"231c592d-72fd-44d4-a977-648284882422"},"source":["data = pd.read_csv(\"/content/drive/My Drive/Duplicate Question Detection/quora_questions.csv\")\n","#data.fillna(\"none value\", inplace=True) # replace nan value to none\n","# drop the rows with null value\n","data.dropna(axis=0, inplace=True)\n","N=len(data)\n","print('Number of question pairs: ', N)\n","data.head()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Number of question pairs:  404348\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  qid1  ...                                          question2 is_duplicate\n","0   0     1  ...  What is the step by step guide to invest in sh...            0\n","1   1     3  ...  What would happen if the Indian government sto...            0\n","2   2     5  ...  How can Internet speed be increased by hacking...            0\n","3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n","4   4     9  ...            Which fish would survive in salt water?            0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"yMLgpExkBY6g"},"source":["# def cut_to_max(text, max_len):\n","#     words = text.split()[:max_len]\n","#     return ' '.join(words)\n","\n","# # test the func\n","# # cut_to_max(' abc test wewe dfd ddd', 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"deYmlI46IvjG"},"source":["# data['question1'] = data['question1'].apply(lambda x: cut_to_max(x, 65))\n","# data['question2'] = data['question2'].apply(lambda x: cut_to_max(x, 65))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"da9RE9hnMcej"},"source":["# for s in data['question1']:\n","#     if len(s.split()) > 63:\n","#         print(s)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ktQColfXYdXS","executionInfo":{"status":"ok","timestamp":1607420558889,"user_tz":-360,"elapsed":4849,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"e856ca6f-3f0e-41a9-bde0-bcd2110e2f8e"},"source":["print(\"dataset labels Distribution\")\n","print(data.is_duplicate.value_counts())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["dataset labels Distribution\n","0    255042\n","1    149306\n","Name: is_duplicate, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gkSQTu7Ypit0"},"source":["We first split the data into a train and test set. The test set will be used later to evaluate our model."]},{"cell_type":"code","metadata":{"id":"dkKiI0gip6Qs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607427526160,"user_tz":-360,"elapsed":4976,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"5c475224-a248-4d95-f337-7f14588a4a32"},"source":["# model selection\n","from sklearn.model_selection import train_test_split\n","data_train , data_test = train_test_split(data, train_size=0.75, random_state=0)\n","len(data_train), len(data_test)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(303261, 101087)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"vJQespJVZJKC"},"source":["# print(\"Train dataset Distribution\")\n","# print(data_train.is_duplicate.value_counts())\n","\n","# print(\"\\n\\nTest dataset Distribution\")\n","# print(data_test.is_duplicate.value_counts())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHpZO58Dss_v","executionInfo":{"status":"ok","timestamp":1607427536175,"user_tz":-360,"elapsed":1278,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["train_Q1 = np.array(data_train['question1'])\n","train_Q2 = np.array(data_train['question2'])\n","t_labels = np.array(data_train['is_duplicate'])\n","# make it one-hot encoding\n","train_labels = tf.keras.utils.to_categorical(t_labels, num_classes=2)\n","\n","test_Q1 = np.array(data_test['question1'])\n","test_Q2 = np.array(data_test['question2'])\n","te_labels  = np.array(data_test['is_duplicate'])\n","# make it one-hot encoding\n","test_labels = tf.keras.utils.to_categorical(te_labels, num_classes=2)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"6t-fu-fL-qf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606903866498,"user_tz":-360,"elapsed":1588,"user":{"displayName":"Moshiur Rahman","photoUrl":"","userId":"06268589185065181981"}},"outputId":"75147e09-88cc-4a50-958f-4b568c5e2776"},"source":["train_Q1.shape, train_Q2.shape, train_labels.shape, test_Q1.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((303261,), (303261,), (303261, 2), (101087,))"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"bz7H3hhIN_8T","executionInfo":{"status":"ok","timestamp":1607427549170,"user_tz":-360,"elapsed":1435,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["# data generator\n","class data_generator(tf.keras.utils.Sequence):\n","    \"\"\"Generates batches of data.\n","\n","    Args:\n","        sentence_pairs: Array of premise and hypothesis input sentences.\n","        labels: Array of labels.\n","        batch_size: Integer batch size.\n","        shuffle: boolean, whether to shuffle the data.\n","        include_targets: boolean, whether to incude the labels.\n","\n","    Returns:\n","        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n","        (or just `[input_ids, attention_mask, `token_type_ids]`\n","         if `include_targets=False`)\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        sentence_pairs,\n","        labels,\n","        batch_size,\n","        shuffle=True,\n","        include_targets=True,\n","    ):\n","        self.sentence_pairs = sentence_pairs\n","        self.labels = labels\n","        self.shuffle = shuffle\n","        self.batch_size = batch_size\n","        self.include_targets = include_targets\n","        # Load our BERT Tokenizer to encode the text.\n","        # We will use base-base-uncased pretrained model.\n","        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n","            \"bert-base-cased\", do_lower_case=False\n","        )\n","        self.indexes = np.arange(len(self.sentence_pairs))\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        # Denotes the number of batches per epoch.\n","        return len(self.sentence_pairs) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        # Retrieves the batch of index.\n","        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        sentence_pairs = self.sentence_pairs[indexes]\n","\n","        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n","        # encoded together and separated by [SEP] token.\n","        encoded = self.tokenizer.batch_encode_plus(\n","            sentence_pairs.tolist(),\n","            add_special_tokens=True,\n","            max_length=max_length,\n","            return_attention_mask=True,\n","            return_token_type_ids=True,\n","            pad_to_max_length=True,\n","            return_tensors=\"tf\",\n","        )\n","\n","        # Convert batch of encoded features to numpy array.\n","        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n","        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n","        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n","\n","        # Set to true if data generator is used for training/validation.\n","        if self.include_targets:\n","            labels = np.array(self.labels[indexes], dtype=\"int32\")\n","            return [input_ids, attention_masks, token_type_ids], labels\n","        else:\n","            return [input_ids, attention_masks, token_type_ids]\n","\n","    def on_epoch_end(self):\n","        # Shuffle indexes after each epoch if shuffle is set to True.\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4O-D3G2OABg","executionInfo":{"status":"ok","timestamp":1607427559972,"user_tz":-360,"elapsed":1621,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["# make a model for detecting duplicate question\n","# max_length = 256\n","# learning_rate = 0.001\n","def duplicate_question_detection_model():\n","\n","    # Encoded token ids from BERT tokenizer.\n","    input_ids = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n","    )\n","\n","    # Attention masks indicates to the model which tokens should be attended to.\n","    attention_masks = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n","    )\n","\n","    # Token type ids are binary masks identifying different sequences in the model.\n","    token_type_ids = tf.keras.layers.Input(\n","        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n","    )\n","\n","     # Loading pretrained BERT model.\n","    bert_model = transformers.TFBertModel.from_pretrained('bert-base-cased', return_dict = False)\n","    # Freeze the BERT model to reuse the pretrained features without modifying them.\n","    bert_model.trainable = True\n","\n","    sequence_output, pooled_output = bert_model(\n","        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n","    )\n","    dropout = tf.keras.layers.Dropout(rate=0.1)(pooled_output)\n","    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n","\n","    # model object\n","    model = tf.keras.models.Model(\n","        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n","    )\n","\n","    # compile the model\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate, epsilon=1e-8),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[\"acc\"],\n","    )\n","\n","    return model\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":611,"referenced_widgets":["b92fef2c773c466a81a673a56f816299","b90adab80af04ea88f6241e6af362a2d","ef84839728654131b88b4b7ee687060a","7010f61fd62e450182d24e4768a4d7a5","bb4fa3191d5048489fb7c449b36804df","54dbaf6998664265a87404ba0927d393","011e593c2f22481d863a3d8be9527653","755747d3bd63495481eb35d569126014","c609b49841f54e069b3327a8c8ece28e","f47edf4d74404a92b709d3fda84166d6","5e67bc35ee984194befe28431d740c85","f9d07429dae149d5a0a32fff2f71ca94","ea0890b272b74206a7c4bddbcfb688e2","d36b461448b94dd39ff3d7f8c5e20da5","df8f4e6e796a4102a2ea3cdbef7fa1a2","b4ce80f442ee4ae09eac29887a11e516"]},"id":"Lk_4aHJPOBIU","executionInfo":{"status":"ok","timestamp":1607427593982,"user_tz":-360,"elapsed":26477,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"0a9dbd7c-572d-48da-e442-57f25755f310"},"source":["# Create the model under a distribution strategy scope.\n","strategy = tf.distribute.MirroredStrategy()\n","\n","with strategy.scope():\n","    max_length=64\n","    learning_rate = 2e-5\n","    model = duplicate_question_detection_model()\n","\n","# print(f\"Strategy: {strategy}\")\n","model.summary()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b92fef2c773c466a81a673a56f816299","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c609b49841f54e069b3327a8c8ece28e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=526681800.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","attention_masks (InputLayer)    [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","token_type_ids (InputLayer)     [(None, 64)]         0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     ((None, 64, 768), (N 108310272   input_ids[0][0]                  \n","                                                                 attention_masks[0][0]            \n","                                                                 token_type_ids[0][0]             \n","__________________________________________________________________________________________________\n","dropout_37 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2)            1538        dropout_37[0][0]                 \n","==================================================================================================\n","Total params: 108,311,810\n","Trainable params: 108,311,810\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2hVoTkYuvSgZ","executionInfo":{"status":"ok","timestamp":1607427614016,"user_tz":-360,"elapsed":12010,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["# data augmentation\n","first_part = data_train[[\"question1\", \"question2\"]].values.astype(\"str\")\n","second_part = data_train[[\"question2\", \"question1\"]].values.astype(\"str\")\n","total_train_data = np.concatenate((first_part, second_part))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"ugwEVmtDy5BE","executionInfo":{"status":"ok","timestamp":1607427627564,"user_tz":-360,"elapsed":2688,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["total_train_labels = np.concatenate((train_labels, train_labels))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTN9S3J9OBWe","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["bc90e96ac81044238f9c5d3208c70cbf","8ddd56f7922a453988b79855449b64c7","566aa8d89c354de99e54e67e765cf664","3d445822690249048e27bb7e5639f221","d4539b61eec24e1d9de2b639e2eda4a8","1bc7832b3bc649279f7ed402ff1d0cdc","5236f3346efd4bee9b4e4124d1c06d42","825607e7d75c48b7aabcc8a155d85175"]},"executionInfo":{"status":"ok","timestamp":1607427648609,"user_tz":-360,"elapsed":3439,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"d3184482-78ac-401d-d14f-08a909c912ea"},"source":["# data preparation\n","batch_size = 32\n","train_data = data_generator(\n","    total_train_data,\n","    total_train_labels,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","valid_data = data_generator(\n","    data_test[[\"question1\", \"question2\"]].values.astype(\"str\"),\n","    test_labels,\n","    batch_size=batch_size,\n","    shuffle=False,\n",")"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc90e96ac81044238f9c5d3208c70cbf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8A0H_EzJkcmu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607427674277,"user_tz":-360,"elapsed":3132,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"dde49b0f-4747-49e2-a9de-6c54bbcfaea9"},"source":["# change learning rate\n","\n","tf.keras.backend.set_value(model.optimizer.lr, 1e-5)\n","print(tf.keras.backend.get_value(model.optimizer.lr))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["1e-05\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16EfvUObOBoy","executionInfo":{"status":"ok","timestamp":1607432597978,"user_tz":-360,"elapsed":1939146,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}},"outputId":"33b0f79f-3426-47d4-a563-1d9615a00d51"},"source":["epochs = 1\n","history = model.fit(\n","    train_data,\n","    validation_data=valid_data,\n","    epochs=epochs,\n","    use_multiprocessing=True,\n","    workers=-1,\n",")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Iterator.get_next_as_optional()` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","18953/18953 [==============================] - ETA: 0s - loss: 0.1141 - acc: 0.9577"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","18953/18953 [==============================] - ETA: 0s - loss: 0.1141 - acc: 0.9577"],"name":"stdout"},{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","18953/18953 [==============================] - 4898s 258ms/step - loss: 0.1141 - acc: 0.9577 - val_loss: 0.2862 - val_acc: 0.9050\n","18953/18953 [==============================] - 4898s 258ms/step - loss: 0.1141 - acc: 0.9577 - val_loss: 0.2862 - val_acc: 0.9050\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IlUUr8FxU-B0","executionInfo":{"status":"ok","timestamp":1607432759896,"user_tz":-360,"elapsed":3504,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["model.save_weights('/content/drive/My Drive/Duplicate Question Detection/Seq_classification/data_augmentation_2_epoch.h5', overwrite=True, save_format=None, options=None)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jy9ZWEhsH63y","executionInfo":{"status":"ok","timestamp":1607427665171,"user_tz":-360,"elapsed":6417,"user":{"displayName":"Md. Moshiur Rahman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBVQvDq8l57ofLdj6VjysLHxPgC3uc6v1yTUoyUA=s64","userId":"13021409582926930931"}}},"source":["model.load_weights('/content/drive/My Drive/Duplicate Question Detection/Seq_classification/data_augmentation_1_epoch.h5', by_name=False, skip_mismatch=False, options=None)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"50Cz1VnCIGWI"},"source":["valid_data = data_generator(\n","    data_test[['question1', 'question2']].values.astype(str),\n","    labels = test_labels,\n","    batch_size = batch_size,\n","    shuffle= False,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"95cVHTbO-beQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606941194433,"user_tz":-360,"elapsed":308032,"user":{"displayName":"Moshiur Rahman","photoUrl":"","userId":"06268589185065181981"}},"outputId":"05d9f61d-04cd-444f-f63e-a4b7309542eb"},"source":["model.evaluate(valid_data, verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["3158/3158 [==============================] - 306s 97ms/step - loss: 0.2729 - acc: 0.9009\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.27293598651885986, 0.9009064435958862]"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"xZGqDER0QLbQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXb8ZbnYPlT9"},"source":["# draw curves \n","import matplotlib.pyplot as plt\n","%pylab inline\n","plt.plot(history.history['loss'], label='train')\n","plt.plot(history.history['val_loss'], label='val')\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(history.history['acc'], label='train')\n","plt.plot(history.history['val_acc'], label='val')\n","plt.xlabel('epochs')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yh1iSIiADOs5"},"source":["# !cp '/content/saved_model_85.h5' '/content/drive/My Drive/Thesis/Duplicate Question/'\n","\n","# from keras.models import load_model\n","\n","# trained_model = load_model('/content/drive/My Drive/Thesis/Duplicate Question/saved_model_85.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NDCcLnd8pqiH"},"source":[""]},{"cell_type":"code","metadata":{"id":"RJnJPJKcVBcC"},"source":[""],"execution_count":null,"outputs":[]}]}